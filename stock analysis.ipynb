{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fef4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Installing collected packages: pyyaml\n",
      "Successfully installed pyyaml-6.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee7f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'https://drive.google.com/drive/folders/1dfLGdGNeHmkuf4-7jZT6KYl6aU-t2v6M?usp=sharing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7001306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8f9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'NiftyStocks/2024_YAML'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a599d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://drive.google.com/drive/folders/1dfLGdGNeHmkuf4-7jZT6KYl6aU-t2v6M?usp=sharing: c:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"https://drive.google.com/drive/folders/1dfLGdGNeHmkuf4-7jZT6KYl6aU-t2v6M?usp=sharing:\", os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "798e30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def extract_yaml_to_csv(yaml_root_folder, output_folder):\n",
    "    if not os.path.exists(yaml_root_folder):\n",
    "        raise FileNotFoundError(f\"YAML folder not found: {yaml_root_folder}\")\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    symbol_data = {}\n",
    "\n",
    "    for month_folder in os.listdir(yaml_root_folder):\n",
    "        month_path = os.path.join(yaml_root_folder, month_folder)\n",
    "        if os.path.isdir(month_path):\n",
    "            for file in os.listdir(month_path):\n",
    "                if file.endswith(\".yaml\") or file.endswith(\".yml\"):\n",
    "                    with open(os.path.join(month_path, file), 'r') as f:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        for entry in data:\n",
    "                            symbol = entry.get(\"symbol\")\n",
    "                            if symbol:\n",
    "                                if symbol not in symbol_data:\n",
    "                                    symbol_data[symbol] = []\n",
    "                                symbol_data[symbol].append(entry)\n",
    "\n",
    "    for symbol, entries in symbol_data.items():\n",
    "        df = pd.DataFrame(entries)\n",
    "        df.to_csv(f\"{output_folder}/{symbol}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad24e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calculate_stock_metrics(csv_folder):\n",
    "    results = []\n",
    "\n",
    "    for file in os.listdir(csv_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            symbol = file.replace(\".csv\", \"\")\n",
    "            df = pd.read_csv(os.path.join(csv_folder, file))\n",
    "\n",
    "            # Ensure date is datetime and sorted\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df = df.sort_values('date')\n",
    "\n",
    "            # Calculate daily return\n",
    "            df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "            # Calculate metrics\n",
    "            volatility = df['daily_return'].std()\n",
    "            cumulative_return = (df['close'].iloc[-1] / df['close'].iloc[0]) - 1\n",
    "            sector = df['sector'].iloc[0] if 'sector' in df.columns else 'Unknown'\n",
    "\n",
    "            results.append({\n",
    "                'symbol': symbol,\n",
    "                'sector': sector,\n",
    "                'volatility': volatility,\n",
    "                'cumulative_return': cumulative_return\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc3b1aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting beautifulsoup4 (from gdown)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from gdown)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->gdown) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2025.1.31)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\sathya computers\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathya computers\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: tqdm, soupsieve, filelock, beautifulsoup4, gdown\n",
      "Successfully installed beautifulsoup4-4.13.3 filelock-3.18.0 gdown-5.2.0 soupsieve-2.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec3eeea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1N5TLYZhRqNN8i-zbrntRTKSx37cJnTZv\n",
      "To: c:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\\your_file_name.zip\n",
      "100%|██████████| 513k/513k [00:00<00:00, 1.01MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'your_file_name.zip'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "file_id = \"1N5TLYZhRqNN8i-zbrntRTKSx37cJnTZv\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = \"your_file_name.zip\"  # Rename as needed\n",
    "\n",
    "gdown.download(url, output, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e7be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1N5TLYZhRqNN8i-zbrntRTKSx37cJnTZv\n",
      "To: c:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\\stock_data.zip\n",
      "100%|██████████| 513k/513k [00:00<00:00, 577kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stock_data.zip'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1N5TLYZhRqNN8i-zbrntRTKSx37cJnTZv/view?usp=drive_link\"\n",
    "output = \"stock_data.zip\"\n",
    "\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3921d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Rar!\\x1a\\x07\\x01\\x00\\xca\\x0b\\x0c\\x8d\\x0c\\x01\\x05\\x08\\x00\\x07\\x01\\x01\\x80\\x80\\x80\\x80\\x00\\x00\"j\\x1e<\\x02\\x03\\x0b\\xa7\\r\\x04\\x9a; \\xc0\\xe7\\x9aV\\x80\\x03\\x00 2024-01/2024-01-01_05-30-00.yaml\\n\\x03\\x02\\x16\\n\\xbbe>?\\xdb\\x01\\xce1\\xa3\\x06@e33C?'\n"
     ]
    }
   ],
   "source": [
    "with open(\"stock_data.zip\", \"rb\") as f:\n",
    "    head = f.read(100)\n",
    "    print(head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02c9ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def analyze_stock_csvs(csv_folder):\n",
    "    results = []\n",
    "\n",
    "    for file in os.listdir(csv_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            symbol = file.replace(\".csv\", \"\")\n",
    "            df = pd.read_csv(os.path.join(csv_folder, file))\n",
    "\n",
    "            # Ensure required columns exist\n",
    "            if 'date' not in df.columns or 'close' not in df.columns:\n",
    "                continue\n",
    "\n",
    "            df['date'] = pd.to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e8a75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def analyze_stock_csvs(csv_folder):\n",
    "    results = []\n",
    "\n",
    "    for file in os.listdir(csv_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            symbol = file.replace(\".csv\", \"\")\n",
    "            df = pd.read_csv(os.path.join(csv_folder, file))\n",
    "\n",
    "            # Ensure required columns exist\n",
    "            if 'date' not in df.columns or 'close' not in df.columns:\n",
    "                continue\n",
    "\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df = df.sort_values('date')\n",
    "\n",
    "            # Calculate daily return\n",
    "            df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "            # Calculate metrics\n",
    "            volatility = df['daily_return'].std()\n",
    "            cumulative_return = (df['close'].iloc[-1] / df['close'].iloc[0]) - 1\n",
    "            sector = df['sector'].iloc[0] if 'sector' in df.columns else 'Unknown'\n",
    "\n",
    "            results.append({\n",
    "                'symbol': symbol,\n",
    "                'sector': sector,\n",
    "                'volatility': round(volatility, 4),\n",
    "                'cumulative_return': round(cumulative_return, 4)\n",
    "            })\n",
    "\n",
    "    # ✅ Don't forget this line!\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "354e0ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "metrics_df = analyze_stock_csvs(\"csv_output\")\n",
    "print(metrics_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88d7407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n",
      "Is a file: True\n",
      "File size: 512856 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "zip_path = r\"C:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\\stock_data.zip\"\n",
    "\n",
    "print(\"File exists:\", os.path.exists(zip_path))\n",
    "print(\"Is a file:\", os.path.isfile(zip_path))\n",
    "print(\"File size:\", os.path.getsize(zip_path), \"bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eac878bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def extract_yaml_to_csv(yaml_root_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    symbol_data = {}\n",
    "\n",
    "    # Traverse all subdirectories and files\n",
    "    for root, dirs, files in os.walk(yaml_root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".yaml\") or file.endswith(\".yml\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                with open(file_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = yaml.safe_load(f)\n",
    "                    except yaml.YAMLError as e:\n",
    "                        print(f\"YAML error in {file_path}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    if not data or 'symbol' not in data:\n",
    "                        print(f\"Missing symbol in {file_path}\")\n",
    "                        continue\n",
    "\n",
    "                    symbol = data['symbol']\n",
    "                    data.pop('symbol', None)  # Remove symbol from data dict\n",
    "\n",
    "                    flat_data = {\"file\": file, **data}\n",
    "\n",
    "                    if symbol not in symbol_data:\n",
    "                        symbol_data[symbol] = []\n",
    "\n",
    "                    symbol_data[symbol].append(flat_data)\n",
    "\n",
    "    # Save each symbol’s data to its own CSV\n",
    "    for symbol, records in symbol_data.items():\n",
    "        df = pd.DataFrame(records)\n",
    "        df.to_csv(os.path.join(output_folder, f\"{symbol}.csv\"), index=False)\n",
    "\n",
    "    print(f\"✅ Conversion completed. CSVs saved to: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfd94e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion completed. CSVs saved to: C:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\\StockCSVs\n"
     ]
    }
   ],
   "source": [
    "yaml_folder_path = r\"C:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\\StockYAMLs\"\n",
    "csv_output_path = r\"C:\\Users\\SATHYA COMPUTERS\\Documents\\strock analysis\\StockCSVs\"\n",
    "\n",
    "extract_yaml_to_csv(yaml_folder_path, csv_output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
